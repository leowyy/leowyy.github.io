---
layout: post
title: Note #1: Clustering Basics
---
### Goal of clustering 
Partition points into disjoint sets such that:
* Points in the same group are similar
* Points in different groups are dissimilar
* Aka graph partition with minimal cut

### Clustering variants
* Similarity-based: input N x N dissimilarity matrix or distance matrix D
* Feature-based: input N x D feature matrix or design matrix X
* Flat clustering: partition into disjoint sets
* Hierarchical clustering: create a nested tree of partitions

### Associated problems
* Multi-view clustering: cluster feature vectors, not data points
* Label prediction: given a point, we aim to predict its label

### Clustering algorithms
* k-means
* Hierarchical clustering
* Gaussian mixtures
* Spectral clustering
* Affinity propagation
* Infinite mixture model (Dirichlet process)

### Clustering metrics
* Graph cuts - cut score & conductance of the graph
* Purity - requires ground truth class labels, does not penalise the number of clusters
* RAND score
* Mutual information

